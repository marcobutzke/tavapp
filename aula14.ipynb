{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 22:14:13.833044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-24 22:14:13.953474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:14:13.953498: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-24 22:14:13.975394: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-24 22:14:14.694100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:14:14.694237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:14:14.694247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather('./tavbase/gs.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learning_dnn(df_dl, dep_var, classes):\n",
    "    # Separa a variável dependente das demais\n",
    "    deep_feat = df_dl.drop(columns=[dep_var], axis=1)\n",
    "    deep_label = df_dl[dep_var]\n",
    "    # Verifica os tipos das variáveis\n",
    "\t    # Verifica as colunas para normalização - as demais serão discretizadas - Função Bucketize do Tensor Flow\n",
    "    categorical_columns = [col for col in deep_feat.columns if len(deep_feat[col].unique()) == 2 or deep_feat[col].dtype == 'O']\n",
    "    continuous_columns = [col for col in deep_feat.columns if len(deep_feat[col].unique()) > 2 and (deep_feat[col].dtype == 'int64' or deep_feat[col].dtype == 'float64')]    \n",
    "    cols_to_scale = continuous_columns[:]\n",
    "    #cols_to_scale.remove('meses')\n",
    "    # Ajusta as bases de treino e de teste\n",
    "    XX_T = df_dl.drop(columns=[dep_var], axis=1)\n",
    "    XX_t = df_dl.drop(columns=[dep_var], axis=1)\n",
    "    yy_T = df_dl[dep_var]\n",
    "    yy_t = df_dl[dep_var]\n",
    "    # Normaliza as variáveis nas bases de treino e teste\n",
    "    scaler = StandardScaler()\n",
    "    XX_T.loc[:, cols_to_scale] = scaler.fit_transform(XX_T.loc[:, cols_to_scale])\n",
    "    XX_t.loc[:, cols_to_scale] = scaler.fit_transform(XX_t.loc[:, cols_to_scale])\n",
    "    # Ajustes das Variáveis Categórica - Não presentes neste modelo\n",
    "    categorical_object_feat_cols = [tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_hash_bucket(key=col, hash_bucket_size=1000), dimension=len(df_dl[col].unique()))\n",
    "    for col in categorical_columns if df_dl[col].dtype == 'O']\n",
    "    # Ajustes das Variáveis Categórica - Não presentes neste modelo\n",
    "    categorical_integer_feat_cols = [tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_identity(key=col, num_buckets=2), dimension=len(df_dl[col].unique()))\n",
    "    for col in categorical_columns if df[col].dtype=='int64']\n",
    "    continuous_feat_cols = [tf.feature_column.numeric_column(key=col) for col in continuous_columns] \n",
    "    feat_cols = categorical_object_feat_cols + \\\n",
    "                categorical_integer_feat_cols + \\\n",
    "                continuous_feat_cols\n",
    "    # Rotina de DNN (Deep Neural Network)\n",
    "    input_fun = tf.compat.v1.estimator.inputs.pandas_input_fn(XX_T, yy_T, batch_size=50, num_epochs=1000, shuffle=True)\n",
    "    pred_input_fun = tf.compat.v1.estimator.inputs.pandas_input_fn(XX_t, batch_size=50, shuffle=False)\n",
    "    DNN_model = tf.estimator.DNNClassifier(hidden_units=[10, 10, 10], feature_columns=feat_cols, n_classes=classes)\n",
    "    DNN_model.train(input_fn=input_fun, steps=5000)\n",
    "    # Resgata os resultados da DNN\n",
    "    predictions = DNN_model.predict(pred_input_fun)\n",
    "    pred = list(predictions)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aula 14 - Probabilidade\n",
    "dimensao = 'Country'\n",
    "medidas = ['Sales', 'Quantity', 'Profit']\n",
    "grupo = data.groupby(dimensao)[medidas].mean().reset_index()\n",
    "grupo['Benefit'] = grupo['Profit'].apply(lambda x : 0 if x < 0 else 1)\n",
    "grupo = grupo.set_index(dimensao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:59: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1367/1181008849.py:33: The name tf.estimator.inputs.pandas_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.pandas_input_fn instead.\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfbxii4nj\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfbxii4nj', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 22:42:49.537836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:42:49.537881: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-24 22:42:49.537904: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (marcobutzke-tavapp-pqizjxmqzbt): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adagrad.py:90: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /workspace/.pyenv_mirror/user/current/lib/python3.8/site-packages/tensorflow/python/training/monitored_session.py:914: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 22:42:50.193859: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-24 22:42:50.202295: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-10-24 22:42:50.209975: W tensorflow/core/common_runtime/forward_type_inference.cc:332] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'dnn/zero_fraction/cond/output/_18'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpfbxii4nj/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.7355423, step = 0\n",
      "INFO:tensorflow:global_step/sec: 504.432\n",
      "INFO:tensorflow:loss = 0.69622976, step = 100 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.953\n",
      "INFO:tensorflow:loss = 0.68157715, step = 200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.74\n",
      "INFO:tensorflow:loss = 0.6602306, step = 300 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.158\n",
      "INFO:tensorflow:loss = 0.65447235, step = 400 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.468\n",
      "INFO:tensorflow:loss = 0.65201867, step = 500 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.322\n",
      "INFO:tensorflow:loss = 0.6244853, step = 600 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.194\n",
      "INFO:tensorflow:loss = 0.62229437, step = 700 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.866\n",
      "INFO:tensorflow:loss = 0.61503625, step = 800 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.228\n",
      "INFO:tensorflow:loss = 0.61753416, step = 900 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.704\n",
      "INFO:tensorflow:loss = 0.62463593, step = 1000 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.975\n",
      "INFO:tensorflow:loss = 0.5990003, step = 1100 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.426\n",
      "INFO:tensorflow:loss = 0.59187657, step = 1200 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 566.634\n",
      "INFO:tensorflow:loss = 0.59341514, step = 1300 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.98\n",
      "INFO:tensorflow:loss = 0.6094191, step = 1400 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.633\n",
      "INFO:tensorflow:loss = 0.57972634, step = 1500 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.393\n",
      "INFO:tensorflow:loss = 0.56444335, step = 1600 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.811\n",
      "INFO:tensorflow:loss = 0.54174095, step = 1700 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 580.808\n",
      "INFO:tensorflow:loss = 0.56511354, step = 1800 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.898\n",
      "INFO:tensorflow:loss = 0.55864453, step = 1900 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 695.463\n",
      "INFO:tensorflow:loss = 0.54517466, step = 2000 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.286\n",
      "INFO:tensorflow:loss = 0.5074577, step = 2100 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.729\n",
      "INFO:tensorflow:loss = 0.54182935, step = 2200 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.21\n",
      "INFO:tensorflow:loss = 0.56385076, step = 2300 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.257\n",
      "INFO:tensorflow:loss = 0.5157274, step = 2400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.557\n",
      "INFO:tensorflow:loss = 0.4769941, step = 2500 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.234\n",
      "INFO:tensorflow:loss = 0.5018938, step = 2600 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 727.265\n",
      "INFO:tensorflow:loss = 0.495065, step = 2700 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.211\n",
      "INFO:tensorflow:loss = 0.51293886, step = 2800 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.791\n",
      "INFO:tensorflow:loss = 0.5093928, step = 2900 (0.155 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2940...\n",
      "INFO:tensorflow:Saving checkpoints for 2940 into /tmp/tmpfbxii4nj/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2940...\n",
      "INFO:tensorflow:Loss for final step: 0.47769728.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfbxii4nj/model.ckpt-2940\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "probabilidade = deep_learning_dnn(grupo, 'Benefit', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Benefit</th>\n",
       "      <th>dl_classe</th>\n",
       "      <th>lucro_0</th>\n",
       "      <th>lucro_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>394.060364</td>\n",
       "      <td>4.145455</td>\n",
       "      <td>99.278182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363380</td>\n",
       "      <td>0.636620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>243.007500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>44.332500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347405</td>\n",
       "      <td>0.652595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>184.140765</td>\n",
       "      <td>2.316327</td>\n",
       "      <td>46.461735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.316185</td>\n",
       "      <td>0.683815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>209.459016</td>\n",
       "      <td>2.598361</td>\n",
       "      <td>53.237459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347605</td>\n",
       "      <td>0.652395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>147.466111</td>\n",
       "      <td>3.856410</td>\n",
       "      <td>-47.932812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461637</td>\n",
       "      <td>0.538363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>137.050668</td>\n",
       "      <td>3.989691</td>\n",
       "      <td>-57.849023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463706</td>\n",
       "      <td>0.536294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>248.302639</td>\n",
       "      <td>3.758491</td>\n",
       "      <td>-7.057474</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.446557</td>\n",
       "      <td>0.553443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>82.190400</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>-123.548600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.448704</td>\n",
       "      <td>0.551296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>255.250000</td>\n",
       "      <td>2.460784</td>\n",
       "      <td>68.644412</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.328345</td>\n",
       "      <td>0.671655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>47.063812</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>-67.859812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.446004</td>\n",
       "      <td>0.553996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country       Sales  Quantity      Profit  Benefit  dl_classe  \\\n",
       "0    Afghanistan  394.060364  4.145455   99.278182        1          1   \n",
       "1        Albania  243.007500  2.500000   44.332500        1          1   \n",
       "2        Algeria  184.140765  2.316327   46.461735        1          1   \n",
       "3         Angola  209.459016  2.598361   53.237459        1          1   \n",
       "4      Argentina  147.466111  3.856410  -47.932812        0          1   \n",
       "..           ...         ...       ...         ...      ...        ...   \n",
       "142    Venezuela  137.050668  3.989691  -57.849023        0          1   \n",
       "143      Vietnam  248.302639  3.758491   -7.057474        0          1   \n",
       "144        Yemen   82.190400  2.366667 -123.548600        0          1   \n",
       "145       Zambia  255.250000  2.460784   68.644412        1          1   \n",
       "146     Zimbabwe   47.063812  2.375000  -67.859812        0          1   \n",
       "\n",
       "      lucro_0   lucro_1  \n",
       "0    0.363380  0.636620  \n",
       "1    0.347405  0.652595  \n",
       "2    0.316185  0.683815  \n",
       "3    0.347605  0.652395  \n",
       "4    0.461637  0.538363  \n",
       "..        ...       ...  \n",
       "142  0.463706  0.536294  \n",
       "143  0.446557  0.553443  \n",
       "144  0.448704  0.551296  \n",
       "145  0.328345  0.671655  \n",
       "146  0.446004  0.553996  \n",
       "\n",
       "[147 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilidade_classe = []\n",
    "for i in range(len(probabilidade)):\n",
    "    probabilidade_classe.append(probabilidade[i][\"class_ids\"][0])\n",
    "probabilidade_prob0 = []\n",
    "for i in range(len(probabilidade)):\n",
    "    probabilidade_prob0.append(probabilidade[i][\"probabilities\"][0])\n",
    "probabilidade_prob1 = []\n",
    "for i in range(len(probabilidade)):\n",
    "    probabilidade_prob1.append(probabilidade[i][\"probabilities\"][1]) \n",
    "grupo['dl_classe'] = probabilidade_classe\n",
    "grupo['lucro_0'] = probabilidade_prob0\n",
    "grupo['lucro_1'] = probabilidade_prob1\n",
    "grupo = grupo.reset_index()\n",
    "grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo.to_feather('./tavbase/probabilidade_pais.feather')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
